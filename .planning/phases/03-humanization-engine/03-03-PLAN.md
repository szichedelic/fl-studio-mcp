---
phase: 03-humanization-engine
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - src/music/humanize/index.ts
  - src/tools/humanize.ts
  - src/tools/index.ts
  - src/tools/notes.ts
autonomous: true

must_haves:
  truths:
    - "User can call humanize_notes MCP tool with a preset name and get humanized notes back"
    - "User can call humanize_notes with custom params (timing, velocity, swing, noteLength) and get fine-grained control"
    - "User can pass humanize preset or params to create_melody, create_chord_progression, create_bass_line and get pre-humanized output"
    - "Pipeline applies transforms in correct order: swing -> timing -> velocity -> note-length"
    - "Humanization returns the seed used so results can be reproduced"
    - "Double-humanization is safe -- humanize always works from input positions, no drift accumulation"
  artifacts:
    - path: "src/music/humanize/index.ts"
      provides: "Main humanize() pipeline composing all four transforms"
      exports: ["humanize"]
    - path: "src/tools/humanize.ts"
      provides: "humanize_notes MCP tool with zod schema"
      exports: ["registerHumanizeTools"]
    - path: "src/tools/index.ts"
      provides: "Updated tool registry including humanize tools"
      contains: "registerHumanizeTools"
    - path: "src/tools/notes.ts"
      provides: "Updated note tools with optional humanize parameter"
      contains: "humanize"
  key_links:
    - from: "src/music/humanize/index.ts"
      to: "src/music/humanize/swing.ts"
      via: "import applySwing"
      pattern: "import.*applySwing.*from.*swing"
    - from: "src/music/humanize/index.ts"
      to: "src/music/humanize/timing.ts"
      via: "import applyTimingDrift"
      pattern: "import.*applyTimingDrift.*from.*timing"
    - from: "src/music/humanize/index.ts"
      to: "src/music/humanize/velocity.ts"
      via: "import applyVelocityVariation"
      pattern: "import.*applyVelocityVariation.*from.*velocity"
    - from: "src/music/humanize/index.ts"
      to: "src/music/humanize/note-length.ts"
      via: "import applyNoteLengthVariation"
      pattern: "import.*applyNoteLengthVariation.*from.*note-length"
    - from: "src/tools/humanize.ts"
      to: "src/music/humanize/index.ts"
      via: "import humanize"
      pattern: "import.*humanize.*from.*humanize/index"
    - from: "src/tools/index.ts"
      to: "src/tools/humanize.ts"
      via: "import registerHumanizeTools"
      pattern: "import.*registerHumanizeTools.*from.*humanize"
---

<objective>
Wire the humanization pipeline together and expose it as MCP tools. Create the main humanize() orchestrator, a standalone humanize_notes MCP tool, and add optional humanize parameters to existing note generation tools.

Purpose: This is the integration layer that makes humanization usable. The pipeline orchestrator composes the four transforms in the correct order. The MCP tools let users humanize via natural language -- either as a post-processing step (humanize_notes) or inline with generation (create_melody with humanize preset).

Output: Updated pipeline index.ts, new MCP tool file, updated tool registry and note tools.
</objective>

<execution_context>
@C:\Users\jared\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jared\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-humanization-engine/03-RESEARCH.md
@.planning/phases/03-humanization-engine/03-01-SUMMARY.md
@.planning/phases/03-humanization-engine/03-02-SUMMARY.md

@src/music/types.ts
@src/music/humanize/util.ts
@src/music/humanize/swing.ts
@src/music/humanize/timing.ts
@src/music/humanize/velocity.ts
@src/music/humanize/note-length.ts
@src/music/humanize/presets.ts
@src/tools/notes.ts
@src/tools/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create humanize pipeline orchestrator</name>
  <files>src/music/humanize/index.ts</files>
  <action>
Create `src/music/humanize/index.ts` -- the main pipeline entry point.

Export `humanize(notes: NoteData[], params?: HumanizationParams): HumanizationResult`.

Implementation:

1. **Resolve preset**: If `params.preset` is set, call `getPresetParams(params.preset)` and deep-merge with any explicit params (explicit params override preset values). Use a simple shallow-merge per sub-object:
   ```typescript
   const resolved = {
     ...presetParams,
     ...params,
     timing: { ...presetParams.timing, ...params.timing },
     velocity: { ...presetParams.velocity, ...params.velocity },
     swing: { ...presetParams.swing, ...params.swing },
     noteLength: { ...presetParams.noteLength, ...params.noteLength },
   };
   ```

2. **Create seeded RNG**: If `params.seed` is provided, use `createSeededRng(params.seed)`. If not, generate a seed from `Date.now().toString(36) + Math.random().toString(36).slice(2, 8)` and use that. Store the seed for the result metadata.

3. **Apply pipeline in order** (CRITICAL: this order matters):
   a. `applySwing(notes, resolved.swing, rng)` -- swing first, defines new grid
   b. `applyTimingDrift(result, resolved.timing, rng)` -- drift around swung positions
   c. `applyVelocityVariation(result, resolved.velocity, rng)` -- dynamics
   d. `applyNoteLengthVariation(result, resolved.noteLength, rng)` -- articulation

4. **Track applied transforms**: Build an `applied: string[]` array noting which transforms actually ran (check `enabled !== false` for each).

5. **Return HumanizationResult**: `{ notes: result, seed, applied }`.

Also re-export key items for convenience:
```typescript
export { humanize } from './index.js';  // (self, but also)
export { getPresetParams, HUMANIZATION_PRESETS } from './presets.js';
export type { HumanizationParams, HumanizationResult, HumanizationPreset } from '../types.js';
```

Wait, since this IS index.ts, just export humanize from this file and re-export the others.

IMPORTANT:
- Never mutate the input `notes` array. The pipeline takes a copy at the start.
- If ALL transforms are disabled (none enabled), return a shallow copy of notes with the seed and empty applied array.
- Use `.js` extensions in all import paths.
  </action>
  <verify>
Run `npx tsc --noEmit` -- zero errors. Verify that `import { humanize } from './music/humanize/index.js'` resolves correctly.
  </verify>
  <done>
humanize/index.ts exports `humanize()` function that composes swing -> timing -> velocity -> note-length in correct order. Supports preset resolution with per-field override. Returns HumanizationResult with notes, seed, and list of applied transforms.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create humanize_notes MCP tool and wire into existing tools</name>
  <files>src/tools/humanize.ts, src/tools/index.ts, src/tools/notes.ts</files>
  <action>
1. Create `src/tools/humanize.ts`:

Export `registerHumanizeTools(server: McpServer, connection: ConnectionManager): void`.

Register ONE tool: `humanize_notes`.

Description: "Humanize MIDI notes with timing drift, velocity variation, swing, and articulation. Makes mechanical patterns sound human. Use presets for quick results or customize individual parameters."

Zod schema for the tool parameters:
```typescript
const humanizeSchema = {
  notes: z.array(z.object({
    midi: z.number().int().min(0).max(127).describe('MIDI note number'),
    time: z.number().min(0).describe('Start time in beats'),
    duration: z.number().min(0.01).describe('Duration in beats'),
    velocity: z.number().min(0).max(1).describe('Velocity 0-1'),
    pan: z.number().min(0).max(1).optional().describe('Pan 0-1'),
    color: z.number().int().min(0).max(15).optional().describe('Note color'),
  })).describe('Notes to humanize'),

  preset: z.enum(['tight', 'loose', 'jazz', 'lo-fi']).optional()
    .describe('Named preset: tight (electronic), loose (relaxed), jazz (swing+drift), lo-fi (wandering)'),

  instrument: z.enum(['drums', 'piano', 'bass', 'synth', 'default']).optional()
    .describe('Instrument velocity profile'),

  swing: z.number().min(50).max(75).optional()
    .describe('Swing amount 50-75 (50=none, 66=triplet, 75=max)'),

  timing_amount: z.number().min(0).max(1).optional()
    .describe('Timing drift amount 0-1 (maps to sigma 0.001-0.025)'),

  seed: z.string().optional()
    .describe('Seed for reproducible results'),

  // Also accept the staged notes option -- humanize and write pyscript
  write_pyscript: z.boolean().default(false).optional()
    .describe('Write humanized notes to .pyscript for FL Studio'),
  channel: z.number().int().min(0).optional()
    .describe('Target channel (only used with write_pyscript)'),
  clearFirst: z.boolean().default(false).optional()
    .describe('Clear existing notes (only used with write_pyscript)'),
};
```

Tool handler implementation:
a. Map the flat schema params to `HumanizationParams`:
   - If `preset` provided, set `params.preset`.
   - If `instrument` provided, set `params.velocity.instrument`.
   - If `swing` provided, set `params.swing = { enabled: true, amount: swing }`.
   - If `timing_amount` provided, map 0-1 to sigma range 0.001-0.025: `sigma = 0.001 + timing_amount * 0.024`. Set `params.timing = { enabled: true, sigma, contextAware: true }`.
   - If `seed` provided, set `params.seed`.
b. Call `humanize(notes as NoteData[], params)`.
c. If `write_pyscript` is true, call `writePyscript('add_notes', result.notes, clearFirst)` and `connection.executeCommand('pianoroll.addNotes', ...)`.
d. Return text response with:
   - How many notes were humanized
   - Which transforms were applied (from result.applied)
   - The seed used (so user can reproduce)
   - If pyscript written, include the TRIGGER_HINT

2. Update `src/tools/index.ts`:

- Add import: `import { registerHumanizeTools } from './humanize.js';`
- Add call: `registerHumanizeTools(server, connection);`
- Update console.error to include 'humanize' in the list.

3. Update `src/tools/notes.ts`:

Add an optional `humanize` parameter to the three generator tools (create_chord_progression, create_melody, create_bass_line). Do NOT add it to add_notes (users should use humanize_notes for raw notes).

For each of the three tools, add to the schema:
```typescript
humanize: z.enum(['tight', 'loose', 'jazz', 'lo-fi']).optional()
  .describe('Apply humanization preset to generated notes'),
humanize_instrument: z.enum(['drums', 'piano', 'bass', 'synth', 'default']).optional()
  .describe('Instrument profile for velocity humanization'),
```

In the tool handler, after generating notes and BEFORE writing pyscript:
```typescript
import { humanize } from '../music/humanize/index.js';

// ... after generating notes:
let finalNotes = notes;
if (humanize_preset) {
  const result = humanize(notes, {
    preset: humanize_preset,
    velocity: humanize_instrument ? { instrument: humanize_instrument } : undefined,
  });
  finalNotes = result.notes;
  // Include humanization info in the response text
}
// Use finalNotes for writePyscript and response
```

IMPORTANT: Be careful with the variable name `humanize` -- the import from the humanize module might conflict with the parameter name. Name the import `humanizeNotes` or similar to avoid collision:
```typescript
import { humanize as humanizeNotes } from '../music/humanize/index.js';
```

IMPORTANT: Use `.js` extensions in all import paths.
  </action>
  <verify>
1. `npx tsc --noEmit` -- zero errors.
2. `npx tsc && node -e "import('./dist/tools/humanize.js').then(m => console.log(Object.keys(m)))"` -- should show registerHumanizeTools.
3. Verify the build output includes the humanize directory: `ls dist/music/humanize/`.
  </verify>
  <done>
humanize_notes MCP tool registered with preset, instrument, swing, timing_amount params. Supports write_pyscript for direct FL Studio staging. create_melody, create_chord_progression, create_bass_line accept optional humanize and humanize_instrument params. Tool registry updated. Project builds and all tools are accessible via MCP.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` compiles with zero errors
2. `npx tsc` produces dist/music/humanize/*.js files
3. All MCP tools registered: transport, state, patterns, notes, humanize
4. humanize_notes tool accepts both preset and custom params
5. Generator tools (melody, chords, bass) accept optional humanize preset
6. Pipeline order verified: swing -> timing -> velocity -> note-length in index.ts
</verification>

<success_criteria>
- humanize() pipeline composes all 4 transforms in correct order (swing -> timing -> velocity -> note-length)
- humanize_notes MCP tool works with presets ("jazz") and custom params (swing: 66, instrument: "drums")
- create_melody, create_chord_progression, create_bass_line accept optional humanize preset
- Seed returned in result for reproducibility
- Project builds cleanly with `npx tsc`
- All existing tools unbroken (add_notes, get_scale_info, clear_notes unchanged)
</success_criteria>

<output>
After completion, create `.planning/phases/03-humanization-engine/03-03-SUMMARY.md`
</output>
