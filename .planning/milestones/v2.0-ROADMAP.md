# Milestone v2.0: Production Pipeline

**Status:** SHIPPED 2026-02-25
**Phases:** 3-7
**Total Plans:** 14

## Overview

Transform note generation into a full creative production toolkit -- humanize MIDI, design sounds in Serum 2, render to audio, and manipulate samples.

## Phases

### Phase 3: Humanization Engine

**Goal**: Generated music sounds human -- timing breathes, dynamics vary, groove feels alive
**Depends on**: Phase 2 (requires NoteData[] to transform)
**Requirements**: HUM-01, HUM-02, HUM-03, HUM-04, HUM-05, HUM-06
**Plans**: 3 plans

Plans:
- [x] 03-01: Types, utilities, swing engine, and O-U timing drift
- [x] 03-02: Velocity profiles, note-length variation, and named presets
- [x] 03-03: Pipeline orchestrator and MCP tool wiring

**Success Criteria:**
1. User can humanize a pattern and hear Brownian-walk timing drift that sounds organic
2. User can apply velocity variation with instrument-appropriate profiles
3. User can apply swing (50-75%) and hear groove shift on off-beat notes
4. User can get context-aware humanization where fast passages stay tight
5. User can select named presets and hear distinctly different humanization character

### Phase 4: Generic Plugin Control

**Goal**: Users can discover and manipulate any loaded VST plugin's parameters by name
**Depends on**: Phase 1 (FL Bridge for SysEx commands)
**Requirements**: PLUG-01, PLUG-02, PLUG-03
**Plans**: 3 plans

Plans:
- [x] 04-01: SysEx response chunking (Python send-side + TypeScript receive-side)
- [x] 04-02: Python plugin handlers + TypeScript param cache and shadow state
- [x] 04-03: MCP plugin tools wiring (discover, get, set by name)

**Success Criteria:**
1. User can ask "what parameters does this plugin have?" and get a filtered list
2. User can set any VST parameter by its name
3. User can read parameter values reliably (shadow state fills gaps)
4. Parameter name resolution survives plugin version updates

### Phase 5: Serum 2 Sound Design

**Goal**: Users can create and shape sounds in Serum 2 using musical language
**Depends on**: Phase 4 (generic plugin control must exist)
**Requirements**: SER-01, SER-02, SER-03, SER-04
**Plans**: 3 plans

Plans:
- [x] 05-01: Runtime discovery spike + Serum types and semantic alias map
- [x] 05-02: Sound design recipes and preset browsing
- [x] 05-03: MCP Serum tools wiring (6 tools)

**Success Criteria:**
1. User can control Serum 2 using semantic names
2. User can say "create a warm pad" and get a recipe applied
3. Fuzzy matching finds the right parameter from approximate names
4. User can browse and load Serum 2 presets

### Phase 6: Audio Rendering Workflow

**Goal**: Users can render MIDI patterns to WAV files with a seamless guided workflow
**Depends on**: Phase 1 (FL Bridge for state reading)
**Requirements**: REN-01, REN-02
**Plans**: 2 plans

Plans:
- [x] 06-01: Install chokidar, audio types, render registry, and WAV file watcher
- [x] 06-02: MCP render tools (render_pattern, list_renders, check_render)

**Success Criteria:**
1. User can say "render this pattern" and receive step-by-step instructions
2. System automatically detects rendered WAV files
3. Rendered files are tracked for downstream sample manipulation

### Phase 7: Sample Manipulation

**Goal**: Users can transform audio samples and execute full resampling workflows
**Depends on**: Phase 6 (needs rendered WAV files as source material)
**Requirements**: SAM-01, SAM-02, SAM-03, SAM-04, SAM-05
**Plans**: 3 plans

Plans:
- [x] 07-01: SoxRunner class, audio types, and file resolution utilities
- [x] 07-02: Basic sample tools (pitch, reverse, timestretch, info)
- [x] 07-03: Stereo detune/layer tool (sample_layer) and final build verification

**Success Criteria:**
1. User can pitch-shift or detune a sample
2. User can reverse or time-stretch a sample
3. User can layer multiple audio files with stereo detune effects
4. User can execute a full resampling workflow

## Milestone Summary

**Key Decisions:**
- Humanization is pure TypeScript pre-processing (zero FL Studio API needed)
- Shadow state for plugin params (getParamValue unreliable for VSTs)
- Audio rendering is guided manual workflow + chokidar file watcher (no render API)
- SoX CLI for audio processing (not browser JS libs)
- O-U Euler-Maruyama for timing drift (correlated, not random)
- Box-Muller hand-rolled instead of Gaussian RNG library (6 lines)
- 685 Serum 2 params discovered; 144 semantic aliases across 16 groups
- SysEx MAX_PAYLOAD_BYTES=1800 for chunking (conservative under 2048 RtMidi buffer)

**Issues Resolved:**
- FLResponse casting bug in plugins.ts (result.data vs result directly)
- Pattern name extraction from state.patterns response (wrong field names)
- chokidar v4 breaking change (error handler uses unknown type)

**Issues Deferred:**
- FL Studio has no programmatic render API (manual Ctrl+R required)
- Sample loading into channels has no API (user drag-and-drop required)

**Technical Debt Incurred:**
- autoDiscover() duplicated between plugins.ts and serum.ts
- connectionManager singleton exported but unused (DI pattern used)
- getAliasGroups() exported but not consumed by any tool

---

_For current project status, see .planning/ROADMAP.md_
